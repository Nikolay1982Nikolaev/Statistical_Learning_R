{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16v6hFq36gCZ"
      },
      "source": [
        "'''\n",
        "# (Very Important) Instructions to get started\n",
        "Please, use a different browser in case you are using *MS Internet Explorer* or *MS Edge* and you experience **mulfunctions**. \n",
        "\n",
        "To **run** or **work** on this [jupyter notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html) you **must** \n",
        "\n",
        "1. **Save the notebook** to your Google Drive. After saving the notebook, you will be able to run it.\n",
        "\n",
        "  * Select **File** / **Save a copy in Drive**  from the Colab menu (an example is below, the notebook name may change)\n",
        "     ![Colab Menu](https://drive.google.com/uc?export=download&id=1-WfIFWuHC6OSJb3iwnR7NqpkXs9tvwO2)\n",
        "  * If required, login with your google account  \n",
        "  ![Signin Button](https://drive.google.com/uc?export=download&id=1yomWF3t03TiPsrp6AAZDXIFpz5XXTvM1)  (any goole account is fine, you can use the campus account or your own gmail account)\n",
        "  \n",
        "\n",
        "2.  Files are usually saved in the  **Colaboratory** *directory* which is located on the root of your google drive. \n",
        "\n",
        "3. To open the notebook again:\n",
        "    * login to the google drive you saved the notebook: [drive.google.com](http://drive.google.com/)\n",
        "    * open the **Colaboratory** directory\n",
        "    * **right click** on the file. From the drop down menu choose **Open With** / **Google Colaboratory**\n",
        "\n",
        "4. In case of problems, please refer to [this document](https://docs.google.com/document/d/1Y-ABvbOQhMvi7COibLJopL-mnPsaCBv_KRr6eKAsnj8/edit?usp=sharing)\n",
        "\n",
        "5. By saving the first colab notebook in gdrive, it is automatically installed a **software extension** which is required to open or create new notebooks in your gdrive\n",
        "\n",
        "# Exercises using Colab, Machine Learning, and ...\n",
        "\n",
        "This is a [jupyter notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html) interface where several elements can be mixed e.g., \n",
        "\n",
        "* Cells containing programs (we will focus on the python programming language),\n",
        "* Inputs and outputs of the computations,\n",
        "* Explanatory text, \n",
        "* Mathematics, \n",
        "* Images,\n",
        "* Rich media representations of objects\n",
        "* ...\n",
        "\n",
        "## Cell Types\n",
        "We will mostly focus on two cell types:\n",
        "\n",
        "* Code\n",
        "* Text \n",
        "\n",
        "## Markdown\n",
        "Contents in **texts cells** can be written using [markdonw syntax](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html). \n",
        "\n",
        "Here it is a quick reference to the markdown syntax: \n",
        "\n",
        "[https://en.support.wordpress.com/markdown-quick-reference/](https://en.support.wordpress.com/markdown-quick-reference/) \n",
        "\n",
        "\n",
        "## Creating an empty Colab\n",
        "Please follows the next steps\n",
        "\n",
        "* Open in a browser the URL [https://drive.google.com/](https://drive.google.com/) \n",
        "\n",
        "* Please choose\n",
        "\n",
        "+ New / More / Colaboratory\n",
        "\n",
        "* Save the notebook in your preferred gdrive location  \n",
        "\n",
        "\n",
        "### COLAB Keyboard Shortcuts\n",
        "To access the COLAB keyboard shortcuts:\n",
        "\n",
        "[Menu] Tools / Keyboard Shortcuts (ctrl to be replaced by Command in the Mac)\n",
        "\n",
        "* Ctrl+M  M     To change a cell into text\n",
        "* Ctrl+M  Y      To change a cell into code\n",
        "* Ctrl+M L       Toggle line numbers\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSwrjcoy6eCe"
      },
      "source": [
        "######\n",
        "# Importing the libraries\n",
        "# They will be described/commented later \n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin # useful for implementing text preprocessing components that can be pipelined\n",
        "import nltk # nltk provides some useful algorithms and data for natural language processing\n",
        "from IPython.display import IFrame # to get a better output on Notebooks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiowKEMA6rve"
      },
      "source": [
        "#######\n",
        "##from IPython.display import IFrame  \n",
        "#gsheetUrl=\"https://docs.google.com/spreadsheets/d/1X6zJNKMWgBsu-Zhe1H3x9smHEz2ft2IZRE0QqTlhDZU/edit?usp=sharing\"\n",
        "#display(IFrame(gsheetUrl, width=1000, height=400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "0iQFmrZq6xrM",
        "outputId": "3ca47fd9-33ec-45cd-9dcc-63676a56d18d"
      },
      "source": [
        "####################################\n",
        "# Functions to load the dataset\n",
        "\n",
        "def loadDataFrame():\n",
        "  # questo e' un url che ci permette di scaricare i dati in formato .csv\n",
        "  # notate nella parte finale dell'url: ?tqx=out:csv&gid=1\n",
        "  # ...out:csv dati disponibili in formato .csv, gid=1 fa riferimento al foglio che avete editato\n",
        "  urlCsv = \"https://docs.google.com/spreadsheets/d/1X6zJNKMWgBsu-Zhe1H3x9smHEz2ft2IZRE0QqTlhDZU/gviz/tq?tqx=out:csv&gid=1\"\n",
        "\n",
        "  # To get more info on pandas read_csv(), please refer to \n",
        "  # https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
        "  df = pd.read_csv(urlCsv, \n",
        "              quoting=0,  # Quoting=0 removes fields surrounding quotes\n",
        "              header=0,           # column names are in the first row (i.e., row 0)\n",
        "              usecols=['Prog.', 'Title', 'ID', 'CategoryID', \n",
        "                      'CategoryName', 'Description'] # loads only the specified columns       \n",
        "                     ) \n",
        "  return df\n",
        "  \n",
        "## In case of emergency\n",
        "\n",
        "def loadDataFrameTsv():\n",
        "  # Link to download the file from the browser (through a splash/lainding page)\n",
        "  # browserLinkSolutions=\"https://drive.google.com/file/d/1CfZHSwElAOHrlgku0x9ybjXAXMwuaqNz/view?usp=sharing\" \n",
        "  #\n",
        "  # next link gives direct access to the file (no splash page) \n",
        "  tsvLinkSolutions=\"https://drive.google.com/uc?export=download&id=1CfZHSwElAOHrlgku0x9ybjXAXMwuaqNz\"\n",
        "  df=pd.read_csv(tsvLinkSolutions, sep='\\t',quoting=0, header=0) # Quoting=0 removes fields surrounding quotes # header=0, column names are in the first row (i.e., row 0))\n",
        "  return df\n",
        "\n",
        "######\n",
        "# Let's load again the data\n",
        "# If you get an error running this cell,\n",
        "# Please execute again the cells containing the definition of \n",
        "# loadDataFrame() and loadDataFrameTsv()\n",
        "\n",
        "df = None \n",
        "df = loadDataFrame()\n",
        "#df = loadDataFrameTsv()\n",
        "\n",
        "if type(df)==type(None) or df.loc[:, 'CategoryID'].isna().sum() >50: \n",
        "  print('Found a lot of NaN, reading emergency dataset') # print is used to show simple values\n",
        "  df = loadDataFrameTsv()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Prog.                                  Title        ID  CategoryID  \\\n",
              "0      1                      Senior Accountant   7269055           1   \n",
              "1      2                   Accounts Semi Senior   1357788           1   \n",
              "2      3  Chef De Partie- Dining Pub-Hungerford   4881772           3   \n",
              "3      4                           Chef Manager   8195384           3   \n",
              "4      5                  Systems Administrator  11094265           2   \n",
              "\n",
              "            CategoryName                                        Description  \n",
              "0            Accountants  A key position has arisen in a long establishe...  \n",
              "1            Accountants  £15.000 - £18.000 (depending on experience) pl...  \n",
              "2                   Chef  Chef de Partie Our client is a beautiful dinin...  \n",
              "3                   Chef  Advert Information Location: Welwyn Garden Cit...  \n",
              "4  System Administrators  Systems Administrator A leading global website...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b28923c-65e6-437e-9003-29b8199e8606\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prog.</th>\n",
              "      <th>Title</th>\n",
              "      <th>ID</th>\n",
              "      <th>CategoryID</th>\n",
              "      <th>CategoryName</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Senior Accountant</td>\n",
              "      <td>7269055</td>\n",
              "      <td>1</td>\n",
              "      <td>Accountants</td>\n",
              "      <td>A key position has arisen in a long establishe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Accounts Semi Senior</td>\n",
              "      <td>1357788</td>\n",
              "      <td>1</td>\n",
              "      <td>Accountants</td>\n",
              "      <td>£15.000 - £18.000 (depending on experience) pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Chef De Partie- Dining Pub-Hungerford</td>\n",
              "      <td>4881772</td>\n",
              "      <td>3</td>\n",
              "      <td>Chef</td>\n",
              "      <td>Chef de Partie Our client is a beautiful dinin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Chef Manager</td>\n",
              "      <td>8195384</td>\n",
              "      <td>3</td>\n",
              "      <td>Chef</td>\n",
              "      <td>Advert Information Location: Welwyn Garden Cit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Systems Administrator</td>\n",
              "      <td>11094265</td>\n",
              "      <td>2</td>\n",
              "      <td>System Administrators</td>\n",
              "      <td>Systems Administrator A leading global website...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b28923c-65e6-437e-9003-29b8199e8606')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4b28923c-65e6-437e-9003-29b8199e8606 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4b28923c-65e6-437e-9003-29b8199e8606');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDeoWmWR7c8Y",
        "outputId": "07520174-6ad0-4aee-afb0-13a67e21b6b4"
      },
      "source": [
        "#####\n",
        "# Improving data quality\n",
        "\n",
        "def improveQuality(parDF):\n",
        "  #Removing NaN \n",
        "  parDF2 = parDF.dropna() # removes lines with NaN (i.e., Null values)\n",
        "\n",
        "  # Converting CategoryID label to int\n",
        "  parDF2.loc[:,'CategoryID'] = parDF2.loc[:,'CategoryID'].astype(int)\n",
        "\n",
        "  # Using only records with permittedLabels in CategoryID\n",
        "  permittedLabels=[1,2,3,4] \n",
        "  # .isin() works well also when values are float while peermittedLabels has int elements\n",
        "  parDF3=parDF2.loc[df.loc[:,'CategoryID'].isin(permittedLabels)]\n",
        "  \n",
        "  return parDF3\n",
        "\n",
        "# Balancing by undersammpling\n",
        "def underSample2Min(df, labelName):\n",
        "    ''' The dataset is undersampled so that all label groups will have the same size,\n",
        "        corresponding to the (original) minimal label set.\n",
        "        The parameter labelName is the DataFrmae column hosting the labels'''\n",
        "        \n",
        "    vc = df.loc[:,labelName].value_counts() # Counting label frequencies\n",
        "    lab2freq = dict(zip(vc.index.tolist(), vc.values.tolist()))\n",
        "    #print(lab2freq) # if you want to see lab2freq, please uncomment this command\n",
        "    #print(min(lab2freq.values()))\n",
        "    minfreq = min(lab2freq.values())\n",
        "    #print(minfreq)\n",
        "    idxSample=[]\n",
        "    for selectedLabel, actualFreq in lab2freq.items():\n",
        "        selIndexes=df.loc[df.loc[:,labelName]==selectedLabel, :].sample(n=minfreq).index.tolist()\n",
        "        idxSample+=selIndexes\n",
        "    idxSample.sort()\n",
        "    #print(type(idxSample), idxSample)\n",
        "    #print(list(df.index)[:5])\n",
        "    \n",
        "    df2 = df.loc[idxSample, :]\n",
        "    #print(len(idxSample), df2.shape);exit()\n",
        "    df2 = df2.reset_index() # otherwise missing index may cause problem\n",
        "    return df2\n",
        "\n",
        "# Performing quality improvement\n",
        "df2 = improveQuality(df)\n",
        "df3 = underSample2Min(df2, 'CategoryID')\n",
        "\n",
        "# Let's check again to the category sizes\n",
        "print('\\nCat. sizes (after undersampling')\n",
        "print(df3.loc[:,'CategoryID'].value_counts())\n",
        "\n",
        "xAll = df3.loc[:, 'Title']\n",
        "yAll = df3.loc[:, 'CategoryID']\n",
        "\n",
        "\n",
        "# Splitting in train-test\n",
        "xTrainVec, xTestVec, yTrain, yTest = train_test_split(\n",
        "    xAll, yAll, # the x and y to be partitioned\n",
        "    test_size=0.30, # the test set size will be 30% of the original dataset, i.e. trainini size will be 70%\n",
        "    random_state=0, # random_state e' il seed del generatore di numeri casuali usato per guidare la partizione in dataset di train e test \n",
        "    stratify=yAll # stratify: tries to ensure a proportional distribution of labels among train and test set\n",
        ")\n",
        "\n",
        "xTrain = list(xTrainVec)\n",
        "xTest = list(xTestVec)\n",
        "print('Ignorate eventuali warning')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cat. sizes (after undersampling\n",
            "3    132\n",
            "2    132\n",
            "1    132\n",
            "4    132\n",
            "Name: CategoryID, dtype: int64\n",
            "Ignorate eventuali warning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4_SHrde7qcj",
        "outputId": "c289209c-5b92-4d38-ab49-7a5fdfecfb7d"
      },
      "source": [
        "######\n",
        "# Simple Pipeline\n",
        "# tockenization and stop words filtering is performed using \n",
        "# CountVectorizer built-in functions\n",
        "\n",
        "# Let's build a pipeline for preprocessing and classifying job vacancy titles\n",
        "cp = Pipeline([  \n",
        "   ('vectorizer', CountVectorizer()),\n",
        "   ('classifier', LogisticRegression() ), # LinearSVC is another classifier you can try\n",
        "                           ])\n",
        "\n",
        "# Racchiudo tutti i valori di configurazione in un'unica struttura dati\n",
        "# il nome di ogni parametro di un componente della pipeline deve essere \n",
        "# preceduto dal nome del componente \n",
        "# separato da 2 underscore \"_\"\n",
        "clsfParams = {\n",
        "   'classifier__C': 0.001,  # C is equivalent to 1/lambda\n",
        "   'classifier__multi_class': 'ovr', # one vs the rest. Strategy to turn a binary classifier into a multil-label classifier\n",
        "   'vectorizer__stop_words':'english', # posso usare [] al posto di 'english' se non voglio usare le stop_words\n",
        "   'vectorizer__ngram_range': (1,1), #only unigrams are considered. (1,2) is for both unigrams and bigrams, (1,3) is for unigrams bigrams and trigrams, ...\n",
        "}\n",
        "\n",
        "# The parameters are set NOW, after pipeline creation\n",
        "# This is strange at the very beginning,\n",
        "# but later you will apreciate it\n",
        "cp.set_params(**clsfParams) \n",
        "cp.fit(xTrain, yTrain)\n",
        "\n",
        "# Performing the prediction\n",
        "yPred=cp.predict(xTest)\n",
        "\n",
        "#Computing the classification report\n",
        "print('Classification report')\n",
        "clasRepSt01 = classification_report(yTest,yPred)\n",
        "print(clasRepSt01)\n",
        "\n",
        "#Computgin accuracy too\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.62      0.74        40\n",
            "           2       0.74      0.93      0.82        40\n",
            "           3       0.93      1.00      0.96        39\n",
            "           4       0.90      0.88      0.89        40\n",
            "\n",
            "    accuracy                           0.86       159\n",
            "   macro avg       0.86      0.86      0.85       159\n",
            "weighted avg       0.86      0.86      0.85       159\n",
            "\n",
            "Accuracy\n",
            "0.8553459119496856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuQnVlMP8UYx"
      },
      "source": [
        "# Improvements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxrnNtxX8QrG"
      },
      "source": [
        "########################\n",
        "# Let's customize (and improve) the preprocessing \n",
        "\n",
        "# seguono delle classi per implementare gestire dei testi\n",
        "\n",
        "class BaseWrapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"class wrapping a sentence processing function so that it can be used in a sklearn.pipeline.Pipeline\"\"\"\n",
        "\n",
        "    def fit(self, x, y=None): #This method is usually overridden in children classes\n",
        "        \"\"\" This method actually does nothing. \n",
        "        It will be overridden by the child classes. \n",
        "        In its children implementations this method will perform all the  \n",
        "        setup activities required before calling either the method transform() \n",
        "        or the method predict().\n",
        "        E.g., a machine learning classifier is trained calling the fit() method, \n",
        "        once trained it can be used to classify new elements by calling the method predict()\n",
        "        \"\"\"\n",
        "        return self\n",
        "\n",
        "    def manageSentence(self, sentence): #This method is usually overridden in children classes\n",
        "        \"\"\"Called by transform(). The sentence is expected to be a either a string or a list of words, \n",
        "        this method can return either a string or a list of words\"\"\"\n",
        "        return sentence \n",
        "    \n",
        "    def transform(self, listOfSentences):\n",
        "        \"\"\" sentenceList: list of sentences.\n",
        "        Every sentence can be either a string or a list of words\n",
        "        Return a list of lists. Each sentence is preprocessed using the manageSentence() method.\n",
        "        Each child class can override the manageSentence() method to implement a specific preprocessing behavior.\n",
        "        The list of preprocessed documents is returned.\"\"\"\n",
        "        toReturn = []\n",
        "        for sentence in listOfSentences:\n",
        "            processedSentence = self.manageSentence(sentence)\n",
        "            toReturn.append(processedSentence)\n",
        "        return toReturn\n",
        "        # using python list comprehension, the above method can be implemented in a single line:\n",
        "        # return [self.manageSentence(sentence) for sentence in listOfSentences]\n",
        "        # more details https://towardsdatascience.com/python-basics-list-comprehensions-631278f22c40\n",
        "\n",
        "class HTMLAccentsReplacer(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Replace html representations of special letters with the corresponding unicode character. \n",
        "        E.g.  &agrave with à.\n",
        "        Args:\n",
        "           * s(string): the string where the html codes should be replaced  \"\"\"\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"HTMLAccentsReplacer Assertion Error\" # if the parameter is not the right type, the execution is interrupted. This is useful to catch errors\n",
        "        # sostituita con la versione seguente piu' completa\n",
        "        replacemap={u'&Ecirc;': u'\\xca', u'&raquo;': u'\\xbb', u'&eth;': u'\\xf0', u'&divide;': u'\\xf7', \n",
        "                    u'&atilde;': u'\\xe3', u'&Aelig;': u'\\xc6', u'&frac34;': u'\\xbe', u'&nbsp;': u' ', \n",
        "                    u'&Aumbl;': u'\\xc4', u'&Ouml;': u'\\xd6', u'&Egrave;': u'\\xc8', u'&Icirc;': u'\\xce', \n",
        "                    u'&deg;': u'\\xb0', u'&ocirc;': u'\\xf4', u'&Ugrave;': u'\\xd9', u'&ndash;': u'\\u2013', \n",
        "                    u'&gt;': u'>', u'&Thorn;': u'\\xde', u'&aring;': u'\\xe5', u'&frac12;': u'\\xbd', \n",
        "                    u'&frac14;': u'\\xbc', u'&Aacute;': u'\\xc1', u'&szlig;': u'\\xdf', u'&trade;': u'\\u2122', \n",
        "                    u'&igrave;': u'\\xec', u'&aelig;': u'\\xe6', u'&times;': u'\\xd7', u'&egrave;': u'\\xe8', \n",
        "                    u'&Atilde;': u'\\xc3', u'&Igrave;': u'\\xcc', u'&Eth;': u'\\xd0', u'&ucirc;': u'\\xfb', \n",
        "                    u'&lsquo;': u'\\u2018', u'&agrave;': u'\\xe0', u'&thorn;': u'\\xfe', u'&Ucirc;': u'\\xdb', \n",
        "                    u'&amp;': u'&', u'&uuml;': u'\\xfc', u'&yuml;': u'', u'&ecirc;': u'\\xea', u'&laquo;': u'\\xab', \n",
        "                    u'&infin;': u'\\u221e', u'&Ograve;': u'\\xd2', u'&oslash;': u'\\xf8', u'&yacute;': u'\\xfd', \n",
        "                    u'&plusmn;': u'\\xb1', u'&icirc;': u'\\xee', u'&auml;': u'\\xe4', u'&ouml;': u'\\xf6', \n",
        "                    u'&Ccedil;': u'\\xc7', u'&euml;': u'\\xeb', u'&lt;': u'<', u'&eacute;': u'\\xe9', \n",
        "                    u'&ntilde;': u'\\xf1', u'&pound;': u'\\xa3', u'&Iuml;': u'\\xcf', u'&Eacute;': u'\\xc9', \n",
        "                    u'&Ntilde;': u'\\xd1', u'&rsquo;': u'\\u2019', u'&euro;': u'\\u20ac', u'&rdquo;': u'\\u201d', \n",
        "                    u'&Acirc;': u'\\xc2', u'&ccedil;': u'\\xe7', u'&Iacute;': u'\\xcd', u'&quot;': u'\"', \n",
        "                    u'&Aring;': u'\\xc5', u'&Oslash;': u'\\xd8', u'&Otilde;': u'\\xd5', u'&Uacute;': u'\\xda', \n",
        "                    u'&reg;': u'\\xae', u'&Yacute;': u'\\xdd', u'&iuml;': u'\\xef', u'&ugrave;': u'\\xf9', \n",
        "                    u'&alpha;': u'\\u03b1', u'&copy;': u'\\xa9', u'&ldquo;': u'\\u201c', u'&oacute;': u'\\xf3', \n",
        "                    u'&Euml;': u'\\xcb', u'&uacute;': u'\\xfa', u'&ograve;': u'\\xf2', u'&acirc;': u'\\xe2', \n",
        "                    u'&aacute;': u'\\xe1', u'&Agrave;': u'\\xc0', u'&Oacute;': u'\\xd3', u'&Uuml;': u'\\xdc', \n",
        "                    u'&iacute;': u'\\xed', u'&cent;': u'\\xa2', u'&Ocirc;': u'\\xd4', u'&mdash;': u'\\u2014', \n",
        "                    u'&otilde;': u'\\xf5', u'&beta;': u'\\u03b2'}\n",
        "        for before in replacemap:\n",
        "            after=replacemap[before] # getting the string to be replaced\n",
        "            sentence=sentence.replace(before, after)\n",
        "        return sentence \n",
        " \n",
        "'''\n",
        "# Required in python2, no more necessary in python3\n",
        "class Str2Unicode(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Converts raw strings to unicode, to better manage accented letters, money symbols (e.g., pounds)\"\"\"\n",
        "        #print(type(sentence), sentence) # ****** cancellami\n",
        "        # if the parameter is not the right type, the execution is interrupted\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"Str2Unicode Assertion Error\"\n",
        "        if type(sentence)==type(u''): # Now it should work also with python3\n",
        "            return sentence\n",
        "        elif type(sentence)==type(''):\n",
        "            return sentence.decode('utf-8', errors='strict')  # interpret all raw strings into unicode\n",
        "        else:\n",
        "            return sentence\n",
        "'''\n",
        "\n",
        "class Tokenizer(BaseWrapper): \n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"This method turn a single document (i.e., a string) into a list of single words (i.e., tokens). \n",
        "        The parameter \"sentence\" is expected to be a string, this method returns a list of strings whereas each string \n",
        "        is a tokenized word. This method replaces all the punctuation with spaces. \n",
        "        Two or more consecuitve spaces are reduced to a single space. \n",
        "        Then the strin is splitted in substring using the spaces as split markers\"\"\"\n",
        "        \n",
        "        if sentence==None:\n",
        "            return[]\n",
        "        # if the parameter is not the right type, the execution is interrupted\n",
        "        assert type(sentence)==type('') or type(sentence)==type(u''), \"Tokenizer Assertion Error\"\n",
        "        punteggiatura=u'!{}[]?\"\",;.:-<>|/\\\\*=+-_% \\n\\t\\r()'+u\"'\" +u'\\u2019'+u'\\u2018' #\\r and \\n can be used as \"new line\" \n",
        "        # Unicode Character 'RIGHT SINGLE QUOTATION MARK' (U+2019)\n",
        "        # \n",
        "        for l in punteggiatura:\n",
        "           #print(s)\n",
        "           sentence=sentence.replace(l,u\" \") #replacing all punctuation characters with spaces           \n",
        "\n",
        "        # loop untill all double spaces are removed\n",
        "        while sentence.find(u\"  \")!=-1:\n",
        "            sentence=sentence.replace(u\"  \",u\" \")  #replacing double spaces with a single one\n",
        "        return sentence.split(u' ')   #e.g., \"a b c d\".split(' ')  returns ['a','b','c','d']\n",
        "\n",
        "class LowerCaseReducer(BaseWrapper): \n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (each item is a string), \n",
        "        this method returns a list of strings whereas each string is the lower case version of the original word\"\"\"\n",
        "        # preliminary check over the input data type\n",
        "        assert type(sentence)==type([]), \"LowerCaseReducer, Assertion Error\" \n",
        "        # The next line uses a python trick called List Comprehensions. \n",
        "        # More details about List Comprehension on http://www.pythonforbeginners.com/basics/list-comprehensions-in-python\n",
        "        return [w.lower() for w in sentence] \n",
        "        # builds a new list, where each word of the original list is turned into a lower case string \n",
        "\n",
        "\n",
        "class EnglishStopWordsRemover(BaseWrapper):\n",
        "    def getStopWords(self):\n",
        "        \"\"\"This method returns a list of English stop words. Stop words can be added to the list\"\"\"\n",
        "        return [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', \n",
        "                u'you', u'your', u'yours', u'yourself', u'yourselves', \n",
        "                u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', \n",
        "                u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', \n",
        "                u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', \n",
        "                u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', \n",
        "                u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', \n",
        "                u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', \n",
        "                u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', \n",
        "                u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', \n",
        "                u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', \n",
        "                u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', \n",
        "                u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', \n",
        "                u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', \n",
        "                u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', \n",
        "                u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n",
        "    \n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word), \n",
        "        this method returns the input list where the stop words are removed \"\"\"\n",
        "        assert type(sentence)==type([]) , \"EnglishStopWordsRemover, Assertion Error\" \n",
        "        stopWords = self.getStopWords()\n",
        "        return [w for w in sentence if w not in stopWords]\n",
        "    \n",
        "class EnglishStemmer(BaseWrapper):\n",
        "    def __init__(self):\n",
        "        \"\"\"Load the NLTK English stemmer. A stemmer is an algorithm that recues a word to its base form \n",
        "        e.g., \"books\" is reduced to \"book\", 'children' is reduced to 'child'. \"\"\"\n",
        "        self.st = nltk.stem.SnowballStemmer(\"english\") # loading the NLTK stemmer\n",
        "    def  manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word), \n",
        "        this method returns a list of stemmed words\"\"\"\n",
        "        assert type(sentence)==type([]), \"EnglishStemmer, Assertion Error\" \n",
        "        return [self.st.stem(w) for w in sentence]\n",
        "\n",
        "# Here it is an examle about stemming\n",
        "#es = EnglishStemmer()\n",
        "#wt = Tokenizer()\n",
        "#res=es.transform(wt.transform([\"we are looking for some new cars\", \"having better performances\"]))\n",
        "#print(res)\n",
        "# [[u'we', u'are', u'look', u'for', u'some', u'new', u'car'], [u'have', u'better', u'perform']]    \n",
        "\n",
        "\n",
        "class RemoveNumbers(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Sentence is expected to be a list of words (a list where each item is a string containing a single word), \n",
        "        this method returns the input list where the numbers are removed. \"\"\"\n",
        "        assert type(sentence)==type([]), \"RemoveNumbers, Assertion Error\" \n",
        "        return [w for w in sentence if w.isdigit()==False]\n",
        "\n",
        "class RemoveEmptyWords(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"Sentence is expected to be a list of words (a list where each item is a string containing a single word), \n",
        "        this method returns the input list where the empty words are removed \"\"\"\n",
        "        assert type(sentence)==type([]), \"RemoveEmptyWords, Assertion Error\" \n",
        "        return [w for w in sentence if not (w==u'' or w=='')]     \n",
        "\n",
        "# No more required. Useful for previous versions of CountVectorizer \n",
        "class Bag2Text(BaseWrapper):\n",
        "    def manageSentence(self, sentence):\n",
        "        \"\"\"sentence is expected to be a list of words (a list where each item is a string containing a single word), \n",
        "        this method returns a single string obtained joining the words and separing them using the space\"\"\"\n",
        "        assert type(sentence)==type([]), \"Bag2Text, Assertion Error\" \n",
        "        # Next line builds a string by joining with spaces all the elements of sentence\n",
        "        return u' '.join(sentence)  \n",
        "\n",
        "def unityFunction(x):\n",
        "  \"\"\"This function returns the same object received as input. \n",
        "  For advanced pythonists: equivalent to lambda x:x \"\"\"\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otuCWERP8lv4",
        "outputId": "1dc7bbe1-e7a8-4341-9574-c036743ea411"
      },
      "source": [
        "######\n",
        "# \n",
        "\n",
        "# Let's build a pipeline for preprocessing and classifying job vacancy titles\n",
        "cp = Pipeline([  \n",
        "   #('Str2Unicode', Str2Unicode()), no more required in Python3\n",
        "   ('HTMLAccentsReplacer', HTMLAccentsReplacer() ),\n",
        "   ('Tokenizer', Tokenizer() ),\n",
        "   ('LowerCaseReducer', LowerCaseReducer() ),\n",
        "   ('StopWordsRemover', EnglishStopWordsRemover() ),\n",
        "   ('Stemmer', EnglishStemmer() ),\n",
        "   ('RemoveNumbers', RemoveNumbers() ),\n",
        "   ('RemoveEmptyWords', RemoveEmptyWords() ),\n",
        "   #('Bag2Text', Bag2Text() ),\n",
        "   ('vectorizer', CountVectorizer()),\n",
        "   ('classifier', LogisticRegression() ), # LinearSVC\n",
        "                           ])\n",
        "\n",
        "# Collecting all the param values in a single data structure. \n",
        "# The parameter keyword should be composed as follows: pipeline_component_name + '__' + param name. \n",
        "clsfParams = {\n",
        "   'classifier__C': 0.001, \n",
        "   #'classifier__multi_class': 'ovr', # one vs the rest. Strategy to turn a binary classifier into a multil-label classifier\n",
        "   'vectorizer__preprocessor': unityFunction, # since we provided a customized preprocessing pipeline, we turn off the usual preprocessing pipeline\n",
        "   'vectorizer__tokenizer': unityFunction, # Same as above. \n",
        "   'vectorizer__ngram_range': (1,1),\n",
        "}\n",
        "\n",
        "cp.set_params(**clsfParams)\n",
        "cp.fit(xTrain, yTrain)\n",
        "\n",
        "yPred=cp.predict(xTest)\n",
        "print('Classification report')\n",
        "clasRepSt02 = classification_report(yTest,yPred)\n",
        "print(clasRepSt02)\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.70      0.79        40\n",
            "           2       0.74      0.93      0.82        40\n",
            "           3       0.95      1.00      0.97        39\n",
            "           4       0.95      0.88      0.91        40\n",
            "\n",
            "    accuracy                           0.87       159\n",
            "   macro avg       0.89      0.88      0.87       159\n",
            "weighted avg       0.88      0.87      0.87       159\n",
            "\n",
            "Accuracy\n",
            "0.8742138364779874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE1hVc2F8nB1",
        "outputId": "52419c77-8bb8-440d-b0a2-5566327c0d28"
      },
      "source": [
        "######\n",
        "# Grid Search\n",
        "\n",
        "# Building the pipeline\n",
        "cp = Pipeline([  \n",
        "   #('Str2Unicode', Str2Unicode()),\n",
        "   ('HTMLAccentsReplacer', HTMLAccentsReplacer() ),\n",
        "   ('Tokenizer', Tokenizer() ),\n",
        "   ('LowerCaseReducer', LowerCaseReducer() ),\n",
        "   ('StopWordsRemover', EnglishStopWordsRemover() ),\n",
        "   ('Stemmer', EnglishStemmer() ),\n",
        "   ('RemoveNumbers', RemoveNumbers() ),\n",
        "   ('RemoveEmptyWords', RemoveEmptyWords() ),\n",
        "   #('Bag2Text', Bag2Text() ),\n",
        "   ('vectorizer', CountVectorizer()),\n",
        "   ('classifier', LogisticRegression() ),  # LinearSVC\n",
        "                           ])\n",
        "\n",
        "# Setting for each parameter the value space (i.e., the set of values to evaluate)\n",
        "paramSpace = {\n",
        "   'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100], # Values for grid search should be enclosed by []\n",
        "   'classifier__multi_class': ['ovr'], # default value, otherwise lot of warnings # one vs the rest. Strategy to turn a binary classifier into a multil-label classifier\n",
        "   'classifier__solver': ['liblinear'],\n",
        "   'classifier__class_weight': [None, 'balanced'], # if the classes were imbalanced, we could try this approach\n",
        "   'vectorizer__preprocessor': [unityFunction], # since we provided a customized preprocessing pipeline, we turn off the usual preprocessing pipeline\n",
        "   'vectorizer__tokenizer': [unityFunction], # Same as above. \n",
        "   'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],   #\n",
        "   'vectorizer__max_df': [0.7],  # If a term is in more of the 70% of documents, it is too frequent to be discriminative\n",
        "   'vectorizer__min_df': [2, 4], # Minimum number of documents where the term should appear (otherwise it won't be considered in the Vocabulary)\n",
        "} # a python list [] is mandatory even if only one element is in \n",
        "\n",
        "start_time = time.time()\n",
        "# cv=4 k-fold validation, con k=4\n",
        "gs = GridSearchCV(cp, param_grid=paramSpace, scoring='accuracy', cv=4)\n",
        "gs.fit(xTrain,yTrain)\n",
        "# ora mostro il tempo di fine\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "print(gs.best_params_)\n",
        "print('Scoring result')\n",
        "print(gs.best_score_)\n",
        "\n",
        "# Please, ignore the warnings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 33.91047286987305 seconds ---\n",
            "{'classifier__C': 1, 'classifier__class_weight': None, 'classifier__multi_class': 'ovr', 'classifier__solver': 'liblinear', 'vectorizer__max_df': 0.7, 'vectorizer__min_df': 4, 'vectorizer__ngram_range': (1, 1), 'vectorizer__preprocessor': <function unityFunction at 0x7f0addf60b90>, 'vectorizer__tokenizer': <function unityFunction at 0x7f0addf60b90>}\n",
            "Scoring result\n",
            "0.9105890603085554\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kwuv0_EC2eK"
      },
      "source": [
        "'''\n",
        "The accuracy value above may be less than the one computed on the test set. One reason is that due to cross-validation, the training set size is less than the one previously used\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT9PkkskCiFi",
        "outputId": "9e9794b4-a93b-436e-bd59-5decde5f0465"
      },
      "source": [
        "######\n",
        "# \n",
        "\n",
        "# Doing classification again, using the best parameters, as selected by Grid Search\n",
        "clsfParams = {\n",
        "   'classifier__C': 1, \n",
        "   'classifier__multi_class': 'ovr', # default value, otherwise lot of warnings # one vs the rest. Strategy to turn a binary classifier into a multil-label classifier\n",
        "   'classifier__solver': 'liblinear',\n",
        "   'vectorizer__preprocessor': unityFunction, # since we provided a customized preprocessing pipeline, we turn off the usual preprocessing pipeline\n",
        "   'vectorizer__tokenizer': unityFunction,\n",
        "   'vectorizer__ngram_range': (1,1),\n",
        "   'vectorizer__min_df': 4,\n",
        "   'vectorizer__max_df': 0.7,\n",
        "}\n",
        "cp.set_params(**clsfParams)\n",
        "cp.fit(xTrain, yTrain)\n",
        "yPred=cp.predict(xTest)\n",
        "print('Classification report')\n",
        "print(classification_report(yTest,yPred))\n",
        "print('Accuracy')\n",
        "print(accuracy_score(yTest,yPred))\n",
        "\n",
        "# What will be the accuracy, in your opinion?\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.72      0.97      0.83        40\n",
            "           2       1.00      0.70      0.82        40\n",
            "           3       0.95      1.00      0.97        39\n",
            "           4       0.97      0.88      0.92        40\n",
            "\n",
            "    accuracy                           0.89       159\n",
            "   macro avg       0.91      0.89      0.89       159\n",
            "weighted avg       0.91      0.89      0.89       159\n",
            "\n",
            "Accuracy\n",
            "0.8867924528301887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLvepSl9Cpkp",
        "outputId": "726cfdc0-c07a-4178-fca0-9d20f26bfe43"
      },
      "source": [
        "print('Visualizziamo nuovamente il primo classification report') \n",
        "print(clasRepSt01)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualizziamo nuovamente il primo classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.62      0.74        40\n",
            "           2       0.74      0.93      0.82        40\n",
            "           3       0.93      1.00      0.96        39\n",
            "           4       0.90      0.88      0.89        40\n",
            "\n",
            "    accuracy                           0.86       159\n",
            "   macro avg       0.86      0.86      0.85       159\n",
            "weighted avg       0.86      0.86      0.85       159\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaIIS3OMDIE7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofniBDPCuIyz"
      },
      "source": [
        "# Link\n",
        "\n",
        "Questo notebook puo' essere scaricato presso\n",
        "\n",
        "[https://colab.research.google.com/drive/1KKTrTlGmp51HcvjjyoINJLbd2av-v-SF?usp=sharing](https://colab.research.google.com/drive/1KKTrTlGmp51HcvjjyoINJLbd2av-v-SF?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80jieZNBuRxn"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}